# upfund-rag

# RAG Microservices â€” Flask API + Streamlit UI (Pinecone)

Deux services **Docker** :

* **backend** : API Flask pour ingestion, retrieval et gÃ©nÃ©ration (RAG)
* **frontend** : UI **Streamlit** type chat (noir/blanc), upload de documents, historique de conversations

**Vector store** : Pinecone (serverless).
**Embeddings** : OpenAI
**Documents** acceptÃ©s : PDF / DOCX / TXT.

---

## ğŸ“¦ Structure du repo

```
upfund-rag/
  backend/
    main.py
    rag_engine.py
    models.py
    ingestion.py
    requirements.txt
    Dockerfile
  frontend/
    app.py
    requirements.txt
    Dockerfile
  data/
    raw_documents/      # ingestion â€œbulkâ€
    user_uploads/       # fichiers uploadÃ©s depuis lâ€™UI (/upload)
  docker-compose.yml
  .env.example
  README.md
```

---

## ğŸ”‘ PrÃ©requis & ClÃ©s API

* Docker & Docker Compose
* Compte **Pinecone** (serverless)
* clÃ© **OpenAI** 

Copie le fichier dâ€™exemple et remplis les clÃ©s :

```bash
cp .env.example .env
```


> ğŸ’¡ **Pinecone** : lâ€™index est crÃ©Ã© Ã  la volÃ©e avec la bonne dimension, soit, 3072 pour OpenAI.

---

## ğŸš€ DÃ©marrage

Depuis la racine du projet :

```bash
docker compose up --build -d
```

Ensuite :

1. DÃ©pose tes docs â€œbulkâ€ dans `data/raw_documents/`
2. Lance lâ€™ingestion (crÃ©ation/rafraÃ®chissement dâ€™index) :

```bash
docker compose exec api python ingestion.py --docs_dir data/raw_documents --clear
```

3. Ouvre lâ€™UI : [http://localhost:8501](http://localhost:8501)

> Tu peux aussi **uploader** des fichiers directement depuis lâ€™UI (section â€œUploadsâ€) â€” ceux-lÃ  sont stockÃ©s dans `data/user_uploads/` et **indexÃ©s** Ã  la volÃ©e.


## ğŸ§± Stack technique

* **Backend** : Python 3.11, Flask, Pydantic, Gunicorn
* **Vector store** : Pinecone (serverless)
* **Embeddings** : OpenAI (`text-embedding-3-large`)
* **LLM** : OpenAI (`gpt-4o-mini` par dÃ©faut) â€” configurable
* **Parsing** : `pypdf`, `python-docx`, `.txt` natif
* **Frontend** : Streamlit (chat minimaliste, noir/blanc, upload, historique)

---

## ğŸ§© Endpoints rÃ©cap

* `GET /healthcheck` â†’ status API + index + namespace
* `POST /ask` â†’ `{question, k}` â†’ `{answer, sources:[{file, chunk_id, score, snippet}]}`
* `POST /reindex` â†’ `{docs_dir?, clear?}`
* `POST /upload` â†’ `multipart/form-data` (`file=@doc.pdf`) â†’ indexation incrÃ©mentale
* `GET /list_user_uploads` â†’ `{"docs":[{"path","size"}]}`

---

## ğŸ§¯ DÃ©pannage

* **`Namespace not found` / `Index not found`**
  â†’ VÃ©rifie `PINECONE_API_KEY`, `PINECONE_INDEX`, `PINECONE_REGION`. Lâ€™index est crÃ©Ã© automatiquement si lâ€™API a les droits.

* **`Vector ID must be ASCII`**
  â†’ Les IDs vectoriels sont normalisÃ©s (slug + hash). Ã‰vite les caractÃ¨res spÃ©ciaux dans les noms de fichiers quand possible.

* **Fichier DOCX â€œ\~\$â€**
  â†’ Ce sont des **verrous Office** temporaires. Ils sont ignorÃ©s Ã  lâ€™ingestion.

* **Pas de nouveaux records aprÃ¨s upload**
  â†’ Regarde les logs backend (`docker compose logs -f api`). Lâ€™upload doit appeler `engine.index_file(save_path, base_dir=data/user_uploads)`.

* **Lâ€™UI ne voit pas les docs**
  â†’ Lâ€™UI liste **uniquement** les fichiers uploadÃ©s via `/upload` (pas `raw_documents`). CÃ´tÃ© Docker, assure-toi que `./data/user_uploads:/app/data/user_uploads:rw` est montÃ© sur **api**.

---
